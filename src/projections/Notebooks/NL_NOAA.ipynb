{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sd2/Moncho/zonalstats_earth_engine/.venv/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tarfile\n",
    "import re\n",
    "\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from glob import glob, iglob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from projections.shapefiles import iter_records\n",
    "from projections import raster, utils\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tifs(tars):\n",
    "    for tar in tars:\n",
    "        names = []\n",
    "\n",
    "        with tarfile.open(tar, 'r') as tf:\n",
    "            # Find gz in tar\n",
    "            names = [x for x in tf.getnames() if x.endswith('.gz') and 'stable_lights' in x]\n",
    "            if not names:\n",
    "                print(f'No stable lights in {tar}')\n",
    "                continue\n",
    "\n",
    "            for name in names:\n",
    "                tf.extract(name, read_path)\n",
    "\n",
    "        for name in names:\n",
    "            # Extract tif\n",
    "            name_path = read_path / name\n",
    "            os.system(f'gunzip {name_path}')\n",
    "\n",
    "            tifs = glob(str(read_path / '*.tif'))\n",
    "\n",
    "            for tif in tifs:\n",
    "                # Yield path to tif file\n",
    "                yield tif\n",
    "\n",
    "            # Clean up\n",
    "            for file in tifs + [name_path]:\n",
    "                try:\n",
    "                    os.remove(file)\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "def save_location_mapping(row_path_tif):\n",
    "    row, path, tif = row_path_tif\n",
    "    IMAGE = utils.read_tif(tif)\n",
    "    shape = row['geometry']\n",
    "    \n",
    "    subset = raster.find_subset_with_intersection_area(IMAGE, shape)\n",
    "\n",
    "    if subset is None:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write('')\n",
    "        return\n",
    "\n",
    "    subset['adm0'] = row['GID_0']\n",
    "    subset['adm1'] = row['GID_1']\n",
    "    subset['adm2'] = row['GID_2']\n",
    "    \n",
    "    subset.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = Path('../Data/Nightlights/')\n",
    "output_path = Path('../Output/Nighlights/')\n",
    "partial_path = utils.make_path(output_path / 'partial_locs')\n",
    "countries_path = utils.make_path(output_path / 'countries')\n",
    "ethnic_path = utils.make_path(output_path / 'ethnic')\n",
    "ethnic_countries_path = utils.make_path(output_path / 'ethnic_countries')\n",
    "\n",
    "tars = sorted(glob(str(read_path / '*.tar')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('../Shapefiles/preprocessed/all_countries.shp')\n",
    "geo_df['GID_1'].fillna(geo_df['GID_0'], inplace=True)\n",
    "geo_df['GID_2'].fillna(geo_df['GID_1'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map raster to polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_from_row(row, path):\n",
    "    name = f'{row[\"GID_2\"]}.csv'\n",
    "    return path / name\n",
    "\n",
    "\n",
    "def get_filename_with_portion_from_row(row, path):\n",
    "    portion = f\"_p{int(row['portion']):03d}\" if row['portion'] else ''\n",
    "    name = f'{row[\"GID_2\"]}{portion}.csv'\n",
    "    return path / name\n",
    "\n",
    "\n",
    "def record_exists(row, path):\n",
    "    return (\n",
    "        get_filename_from_row(row, path).exists() or \n",
    "        get_filename_with_portion_from_row(row, path).exists()\n",
    "    )\n",
    "\n",
    "\n",
    "def yield_missing_records(records, save_path, tif=None):\n",
    "    for _, row in records.iterrows():\n",
    "        if record_exists(row, save_path):\n",
    "            continue\n",
    "            \n",
    "        yield row, get_filename_with_portion_from_row(row, save_path), tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gzip: ../Data/Nightlights/F101992.v4b_web.stable_lights.avg_vis.tif already exists;\tnot overwritten\n",
      "  0%|▏                                     | 503/117719 [00:09<37:37, 51.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Only need to map the locations once\n",
    "# Still loop for the clean up\n",
    "n_processes = 20\n",
    "for tif in load_tifs(tars[:1]):\n",
    "    processing_function = partial(save_location_mapping)\n",
    "    country_iterator = partial(yield_missing_records, save_path=partial_path, tif=tif)\n",
    "    \n",
    "    if n_processes == 1:\n",
    "        for blob in tqdm(country_iterator(geo_df)):\n",
    "            processing_function(blob)\n",
    "    else:\n",
    "        with ProcessPoolExecutor(n_processes) as tpe:\n",
    "            for _ in tqdm(tpe.map(processing_function, country_iterator(geo_df)), \n",
    "                          total=geo_df.shape[0]):\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 414/414 [11:53<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "gid_with_portions = geo_df.loc[geo_df['portion'].notnull(), 'GID_2'].unique()\n",
    "for gid in tqdm(gid_with_portions):\n",
    "    files = list(partial_path.glob(f'{gid}_p*.csv'))\n",
    "    if not files:\n",
    "        continue\n",
    "        \n",
    "    portions = [utils.read_csv(file) for file in files]\n",
    "    portions = [x for x in portions if not x.empty]\n",
    "    \n",
    "    if not portions:\n",
    "        continue\n",
    "    elif len(portions) == 1:\n",
    "        country = portions[0]\n",
    "    else:\n",
    "        county = portions[0].append(portions[1:], ignore_index=True)\n",
    "        \n",
    "    county = county.groupby(['lat', 'lon']).sum().reset_index()\n",
    "    for i in range(3):\n",
    "        county[f'adm{i}'] = portions[0].iloc[0][f'adm{i}']\n",
    "    county.to_csv(partial_path / f'{gid}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_portion(name):\n",
    "    match = re.match('.*_p\\d\\d\\d.csv$', name)\n",
    "    return match is not None\n",
    "\n",
    "\n",
    "def get_files_by_country(path):\n",
    "    files_by_country = {}\n",
    "    for file in path.glob('*.csv'):\n",
    "        if is_portion(file.name):\n",
    "            continue\n",
    "            \n",
    "        file = Path(file)\n",
    "        country = file.name[:3]\n",
    "        if country in files_by_country:\n",
    "            files_by_country[country].append(file)\n",
    "        else:\n",
    "            files_by_country[country] = [file]\n",
    "            \n",
    "    return files_by_country\n",
    "\n",
    "\n",
    "def get_year_from_tif(tif):\n",
    "    return int(Path(tif).name[3:7])\n",
    "\n",
    "\n",
    "def aggregate_and_save(results, tif, save_path, name, groupby):\n",
    "    year = Path(tif).name[3:7]    \n",
    "    \n",
    "    if '{year}' in name:\n",
    "        name = name.format(year=year)\n",
    "        \n",
    "    save_path = save_path / name\n",
    "\n",
    "    if save_path.exists():\n",
    "        return False\n",
    "\n",
    "    # Get raster subset\n",
    "    mask = results['lon'] > -999\n",
    "    \n",
    "    if mask.sum() > 0:\n",
    "        IMAGE = utils.read_tif(tif)\n",
    "        increment = raster.get_increment_from_tif(IMAGE)\n",
    "        \n",
    "        shape = MagicMock()\n",
    "        shape.bounds = (\n",
    "            results.loc[mask, 'lon'].min() - increment,\n",
    "            results.loc[mask, 'lat'].min() - increment,\n",
    "            results['lon'].max() + increment,\n",
    "            results['lat'].max() + increment\n",
    "        )\n",
    "\n",
    "        subset = raster.get_df_by_maximum_bounds(IMAGE, shape, geo=False)\n",
    "        subset['lon'] = np.round(subset['lon'], 6)\n",
    "        subset['lat'] = np.round(subset['lat'], 6)\n",
    "\n",
    "        # Combine with results\n",
    "        if 'value' in results.columns:\n",
    "            results.drop(columns='value', inplace=True)\n",
    "        tresults = results.merge(subset, on=['lon', 'lat'], how='left')\n",
    "        tresults['value'].fillna(0, inplace=True)  # This fills the -999\n",
    "    else:\n",
    "        tresults = results.copy()\n",
    "        tresults['value'] = 0\n",
    "\n",
    "    # Aggregate\n",
    "    pivot = tresults.groupby(groupby)[['intersection_area', 'value']].sum()\n",
    "    pivot['year'] = int(year)\n",
    "\n",
    "    # Save\n",
    "    pivot.reset_index().to_csv(save_path, index=False)\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def load_nl_files(files):\n",
    "    results = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "            \n",
    "        if df.empty or 'intersection_area' not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            results.append(df[pd.to_numeric(df['intersection_area']) > 0])    \n",
    "        except Exception as e:\n",
    "            print(df.columns)\n",
    "            print(file)\n",
    "            raise e\n",
    "        \n",
    "    results = results[0].append(results[1:], ignore_index=True)\n",
    "    results['lon'] = np.round(results['lon'], 6)\n",
    "    results['lat'] = np.round(results['lat'], 6)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def iter_files_by_country(files_by_country, tif, path):\n",
    "    for country, files in files_by_country.items():\n",
    "        year = get_year_from_tif(tif)\n",
    "        name = f'{country}_{year}.csv'\n",
    "        if (path / name).exists():\n",
    "            continue\n",
    "            \n",
    "        yield country, files, name, tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Data/Nightlights/F101992.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F101993.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F121994.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F121995.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F121996.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F141997.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F141998.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F141999.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F152000.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F152001.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F152002.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F152003.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F162004.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F162005.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F162006.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F162007.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F162008.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F162009.v4b_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F182010.v4d_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F182011.v4c_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F182012.v4c_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n",
      "../Data/Nightlights/F182013.v4c_web.stable_lights.avg_vis.tif: 100%|█| 256/256 [\n"
     ]
    }
   ],
   "source": [
    "def load_aggregate_and_save(blob):\n",
    "    country, files, name, tif_name = blob    \n",
    "    \n",
    "    # Load polygons\n",
    "    results = load_nl_files(files)\n",
    "    results['adm1'].fillna('', inplace=True)\n",
    "    results['adm2'].fillna('', inplace=True)\n",
    "    results.drop_duplicates(inplace=True)\n",
    "\n",
    "    aggregate_and_save(results, tif, countries_path, name, groupby=['adm0', 'adm1', 'adm2'])\n",
    "\n",
    "    \n",
    "n_processes = 5\n",
    "files_by_country = get_files_by_country(partial_path)\n",
    "\n",
    "for tif in load_tifs(tars):\n",
    "    with ProcessPoolExecutor(n_processes) as tpe:\n",
    "        for _ in tqdm(tpe.map(load_aggregate_and_save, \n",
    "                              iter_files_by_country(files_by_country, tif, countries_path)), \n",
    "                      total=len(files_by_country), desc=tif):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5632it [00:12, 448.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1027994, 6)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for file in tqdm(countries_path.glob('*.csv')):\n",
    "    df = utils.read_csv(file)\n",
    "    if not df.empty:\n",
    "        results.append(df)\n",
    "        \n",
    "results = results[0].append(results[1:], ignore_index=True)\n",
    "print(results.shape)\n",
    "results.to_csv(output_path / 'nightlights.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adm0</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>intersection_area</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB.10_1</td>\n",
       "      <td>ALB.10.1_1</td>\n",
       "      <td>1.147588e+09</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB.10_1</td>\n",
       "      <td>ALB.10.2_1</td>\n",
       "      <td>1.056770e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB.10_1</td>\n",
       "      <td>ALB.10.3_1</td>\n",
       "      <td>1.301028e+09</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB.11_1</td>\n",
       "      <td>ALB.11.1_1</td>\n",
       "      <td>4.093430e+08</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB.11_1</td>\n",
       "      <td>ALB.11.2_1</td>\n",
       "      <td>1.227538e+09</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adm0      adm1        adm2  intersection_area   value  year\n",
       "0  ALB  ALB.10_1  ALB.10.1_1       1.147588e+09    70.0  1992\n",
       "1  ALB  ALB.10_1  ALB.10.2_1       1.056770e+09     0.0  1992\n",
       "2  ALB  ALB.10_1  ALB.10.3_1       1.301028e+09   594.0  1992\n",
       "3  ALB  ALB.11_1  ALB.11.1_1       4.093430e+08   290.0  1992\n",
       "4  ALB  ALB.11_1  ALB.11.2_1       1.227538e+09  3004.0  1992"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(output_path / 'nightlights.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnic\n",
    "# Map raster to Ethnic locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_records(adm, save_path):\n",
    "    for _, row in tqdm(adm.iterrows(), total=adm.shape[0]):\n",
    "        name = f'{row[\"GID_0\"]}_{row[\"NAME\"]}.csv'\n",
    "        name_path = Path(save_path) / name\n",
    "            \n",
    "        yield row, name_path\n",
    "\n",
    "def iter_and_skip_records(adm, save_path, tif):\n",
    "    for row, name_path in iter_records(adm, save_path):\n",
    "        if name_path.exists():\n",
    "            continue\n",
    "            \n",
    "        yield row, name_path, tif   \n",
    "        \n",
    "\n",
    "def save_location_mapping(blob):\n",
    "    row, name_path, tif = blob\n",
    "    shape = row['geometry']\n",
    "    \n",
    "    IMAGE = utils.read_tif(tif)\n",
    "    subset = raster.find_subset_with_intersection_area(IMAGE, shape)\n",
    "    if subset is None:\n",
    "        print('No intersection found for', name_path)\n",
    "        with open(name_path, 'w') as f:\n",
    "            f.write('')\n",
    "        return\n",
    "\n",
    "    for col in ['NAME', 'TRIBE_CODE', 'GID_0']:\n",
    "        subset[col] = row[col]\n",
    "    \n",
    "    subset.to_csv(name_path, index=False)\n",
    "    \n",
    "# Load shapes\n",
    "adm = gpd.read_file('../Shapefiles/ethnic_preprocessed/tribe_adm0_s.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gzip: ../Data/Nightlights/F101992.v4b_web.stable_lights.avg_vis.tif already exists;\tnot overwritten\n",
      "100%|█████████████████████████████████████| 5053/5053 [00:02<00:00, 2093.35it/s]\n",
      "  0%|                                         | 12/5053 [00:06<43:11,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Map locations\n",
    "n_processes = 15\n",
    "for tif in load_tifs(tars[:1]):    \n",
    "    i = partial(iter_and_skip_records, save_path=ethnic_path, tif=tif)\n",
    "    \n",
    "    if n_processes == 1:\n",
    "        for blob in i(adm):\n",
    "            save_location_mapping(blob)\n",
    "    else:\n",
    "        with ProcessPoolExecutor(n_processes) as tpe:\n",
    "            for _ in tqdm(tpe.map(save_location_mapping, i(adm)), total=adm.shape[0]):\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 134/134 [00:00<00:00, 915.85it/s]\n"
     ]
    }
   ],
   "source": [
    "gid_with_portions = adm.loc[adm['portion'].notnull(), ['GID_0', 'NAME']].agg('_'.join, axis=1).unique()\n",
    "for gid in tqdm(gid_with_portions):\n",
    "    files = list(ethnic_path.glob(f'{gid}_p*.csv'))\n",
    "    if not files:\n",
    "        continue\n",
    "        \n",
    "    portions = [utils.read_csv(file) for file in files]\n",
    "    portions = [x for x in portions if not x.empty]\n",
    "    \n",
    "    if not portions:\n",
    "        continue\n",
    "    elif len(portions) == 1:\n",
    "        country = portions[0]\n",
    "    else:\n",
    "        country = portions[0].append(portions[1:], ignore_index=True)\n",
    "        \n",
    "    country = country.groupby(['lat', 'lon']).sum().reset_index()\n",
    "    l\n",
    "    for i in range(3):\n",
    "        country[f'adm{i}'] = portions[0].iloc[0][f'adm{i}']\n",
    "    country.to_csv(partial_path / f'{gid}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate ethnic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Output/Nighlights/ethnic/MRT_BERABISH.csv\n"
     ]
    }
   ],
   "source": [
    "# for file in ethnic_path.glob('*.csv'):\n",
    "#     f = pd.read_csv(file)\n",
    "#     if (\n",
    "#         str(f['lon'].dtype) != 'float64' \n",
    "#         or str(f['lat'].dtype) != 'float64'\n",
    "#         or f['lon'].max() > 50000\n",
    "#         or f['lat'].max() > 20000\n",
    "#     ):\n",
    "#         os.remove(file)\n",
    "#         print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Data/Nightlights/F101992.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F101993.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F121994.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F121995.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F121996.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F141997.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F141998.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F141999.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F152000.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F152001.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F152002.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F152003.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F162004.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F162005.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F162006.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F162007.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F162008.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F162009.v4b_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F182010.v4d_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F182011.v4c_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F182012.v4c_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n",
      "../Data/Nightlights/F182013.v4c_web.stable_lights.avg_vis.tif: 100%|█| 57/57 [00\n"
     ]
    }
   ],
   "source": [
    "def ethnic_load_aggregate_and_save(blob):\n",
    "    groupby = ['NAME', 'TRIBE_CODE', 'GID_0']\n",
    "    country, files, name, tif_name = blob    \n",
    "    \n",
    "    # Load polygons\n",
    "    results = load_nl_files(files)\n",
    "    for col in groupby:\n",
    "        results[col].fillna('', inplace=True)\n",
    "    results.drop_duplicates(inplace=True)\n",
    "\n",
    "    aggregate_and_save(results, tif_name, ethnic_countries_path, name, groupby=groupby)\n",
    "\n",
    "\n",
    "files_by_country = get_files_by_country(ethnic_path)\n",
    "\n",
    "n_processes = 10\n",
    "with ProcessPoolExecutor(n_processes) as tpe:\n",
    "    for tif in load_tifs(tars):\n",
    "        for _ in tqdm(tpe.map(ethnic_load_aggregate_and_save, \n",
    "                              iter_files_by_country(files_by_country, tif, ethnic_countries_path)), \n",
    "                      total=len(files_by_country), desc=tif):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1254it [00:01, 633.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31064, 6)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for file in tqdm(ethnic_countries_path.glob('*.csv')):\n",
    "    try:\n",
    "        results.append(pd.read_csv(file))\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "results = results[0].append(results[1:], ignore_index=True)\n",
    "print(results.shape)\n",
    "results.drop_duplicates(['NAME', 'GID_0', 'year']).to_csv(output_path / 'nightlights_ethnic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
