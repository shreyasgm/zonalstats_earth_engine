{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisdasilva/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "import shapefile\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from projections.shapefiles import load_shapes, iter_records\n",
    "from projections.models import Records\n",
    "from projections import raster, utils\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = 'lon'\n",
    "lat = 'lat'\n",
    "country = 'country'\n",
    "output_folder = Path('../Output/Precipitaciones/Raster/GPCC/')\n",
    "ethnic_folder = Path('../Output/Precipitaciones/Raster/GPCC_ethnic/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:09<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3787420, 2)\n",
      "Unique locs (291340, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-120.125</td>\n",
       "      <td>85.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-119.875</td>\n",
       "      <td>85.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.625</td>\n",
       "      <td>85.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-120.125</td>\n",
       "      <td>85.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-119.875</td>\n",
       "      <td>85.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lon     lat\n",
       "0 -120.125  85.875\n",
       "1 -119.875  85.875\n",
       "2 -119.625  85.875\n",
       "3 -120.125  85.625\n",
       "4 -119.875  85.625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in tqdm(glob('../Data/Precipitaciones/full_data_monthly_v2020_*.csv')):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df[['lon', 'lat']].copy())\n",
    "    del df\n",
    "    \n",
    "df = dfs[0].append(dfs[1:])\n",
    "del dfs\n",
    "\n",
    "print(df.shape)\n",
    "print('Unique locs', df.drop_duplicates(['lon', 'lat']).shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separation: {'lat': 0.25, 'lon': 0.25}\n",
      "Converting to GeoDataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>adm0</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>raster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-120.125</td>\n",
       "      <td>85.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-120.12500 85.87500)</td>\n",
       "      <td>POLYGON ((-120.00000 86.00000, -120.00000 85.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-119.875</td>\n",
       "      <td>85.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-119.87500 85.87500)</td>\n",
       "      <td>POLYGON ((-119.75000 86.00000, -119.75000 85.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.625</td>\n",
       "      <td>85.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-119.62500 85.87500)</td>\n",
       "      <td>POLYGON ((-119.50000 86.00000, -119.50000 85.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-120.125</td>\n",
       "      <td>85.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-120.12500 85.62500)</td>\n",
       "      <td>POLYGON ((-120.00000 85.75000, -120.00000 85.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-119.875</td>\n",
       "      <td>85.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-119.87500 85.62500)</td>\n",
       "      <td>POLYGON ((-119.75000 85.75000, -119.75000 85.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lon     lat  adm0  adm1  adm2                     geometry  \\\n",
       "0 -120.125  85.875   NaN   NaN   NaN  POINT (-120.12500 85.87500)   \n",
       "1 -119.875  85.875   NaN   NaN   NaN  POINT (-119.87500 85.87500)   \n",
       "2 -119.625  85.875   NaN   NaN   NaN  POINT (-119.62500 85.87500)   \n",
       "3 -120.125  85.625   NaN   NaN   NaN  POINT (-120.12500 85.62500)   \n",
       "4 -119.875  85.625   NaN   NaN   NaN  POINT (-119.87500 85.62500)   \n",
       "\n",
       "                                              raster  \n",
       "0  POLYGON ((-120.00000 86.00000, -120.00000 85.7...  \n",
       "1  POLYGON ((-119.75000 86.00000, -119.75000 85.7...  \n",
       "2  POLYGON ((-119.50000 86.00000, -119.50000 85.7...  \n",
       "3  POLYGON ((-120.00000 85.75000, -120.00000 85.5...  \n",
       "4  POLYGON ((-119.75000 85.75000, -119.75000 85.5...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    locs = pd.read_csv(output_folder / 'unique_locs_gpcc.csv')\n",
    "except FileNotFoundError:\n",
    "    print('File not found, loading locs from df')\n",
    "    locs = df[[lon, lat]].drop_duplicates()\n",
    "    locs.loc[:, 'adm0'] = np.nan\n",
    "    locs.loc[:, 'adm1'] = np.nan\n",
    "    locs.loc[:, 'adm2'] = np.nan\n",
    "    locs.to_csv(output_folder / 'unique_locs_gpcc.csv', index=False)\n",
    "    \n",
    "locs = raster.create_by_separation(locs, lat='lat', lon='lon')\n",
    "locs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [02:18<00:00,  1.99it/s]\n"
     ]
    }
   ],
   "source": [
    "shapes = load_shapes('../Shapefiles/preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separation: {'lat': 0.25, 'lon': 0.25}\n",
      "Converting to GeoDataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping polygons: 100%|██████████| 147767/147767 [3:42:03<00:00, 11.09it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending\n",
      "Saving\n",
      "(357836, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>intersection_ratio</th>\n",
       "      <th>adm0</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.875</td>\n",
       "      <td>72.875</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>MDV</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.875</td>\n",
       "      <td>73.125</td>\n",
       "      <td>0.024442</td>\n",
       "      <td>MDV</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.625</td>\n",
       "      <td>72.875</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>MDV</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.625</td>\n",
       "      <td>73.125</td>\n",
       "      <td>0.020311</td>\n",
       "      <td>MDV</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.375</td>\n",
       "      <td>72.875</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>MDV</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lat     lon  intersection_ratio adm0 adm1 adm2\n",
       "0  6.875  72.875            0.004304  MDV          \n",
       "1  6.875  73.125            0.024442  MDV          \n",
       "2  6.625  72.875            0.008656  MDV          \n",
       "3  6.625  73.125            0.020311  MDV          \n",
       "4  6.375  72.875            0.004036  MDV          "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create rasters from point\n",
    "results = []\n",
    "for pol, record in iter_records(shapes):    \n",
    "    subdf = raster.intersection_ratio(locs, pol)\n",
    "    if subdf is None:\n",
    "        continue\n",
    "\n",
    "    # Add record information\n",
    "    subdf['adm0'] = record[0]\n",
    "    subdf['adm1'] = record[1]\n",
    "    subdf['adm2'] = record[2]\n",
    "    \n",
    "    results.append(subdf)\n",
    "    \n",
    "print('Appending')\n",
    "results = results[0].append(results[1:], ignore_index=True)\n",
    "results.drop_duplicates(inplace=True)\n",
    "\n",
    "print('Saving')\n",
    "results.to_csv(output_folder / 'loc_map.csv', index=False)\n",
    "print(results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_data_monthly_v2020_1891_1900_025.csv\n",
      "full_data_monthly_v2020_1901_1910_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [00:58<00:00,  9.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1911_1920_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:01<00:00, 10.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1921_1930_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:02<00:00, 10.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1931_1940_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:01<00:00, 10.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1941_1950_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:03<00:00, 10.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1951_1960_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:02<00:00, 10.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1961_1970_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:02<00:00, 10.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1971_1980_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:02<00:00, 10.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1981_1990_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:04<00:00, 10.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_1991_2000_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:05<00:00, 10.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_2001_2010_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [01:03<00:00, 10.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958200, 9)\n",
      "full_data_monthly_v2020_2011_2019_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 6/6 [00:56<00:00,  9.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3562380, 9)\n"
     ]
    }
   ],
   "source": [
    "locs = pd.read_csv(output_folder / 'loc_map.csv').fillna('NA')\n",
    "assert locs.duplicated().sum() == 0\n",
    "\n",
    "\n",
    "time_groups = {'yearly': ['year'], 'monthly': ['year', 'month']}\n",
    "loc_groups = {'country': ['adm0'], \n",
    "              'edo': ['adm0', 'adm1'], \n",
    "              'mun': ['adm0', 'adm1', 'adm2']}\n",
    "\n",
    "groups = {}\n",
    "for loc_name, loc_group in loc_groups.items():\n",
    "    for time_name, time_group in time_groups.items():\n",
    "        groups[f'{loc_name}_{time_name}'] = loc_group + time_group\n",
    "        \n",
    "done = [Path(x).name for x in glob(str(output_folder / 'GPCC_*.csv'))]\n",
    "\n",
    "files = sorted(glob('../Data/Precipitaciones/full_data_monthly_v2020_*.csv'))\n",
    "for i, file in enumerate(files):\n",
    "    file = Path(file)\n",
    "    print(file.name)\n",
    "    \n",
    "    from_year, to_year = file.name.split('_')[-3:-1] \n",
    "    full_name = f'GPCC_full_{from_year}_{to_year}.csv'\n",
    "    if full_name in done:\n",
    "        continue\n",
    "    \n",
    "    # Read file and merge locations back\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.merge(locs, on=['lat', 'lon'])\n",
    "    \n",
    "    # Reshape to long\n",
    "    pivot = raster.weighted_pivot(df, value_name='precipitation')\n",
    "    \n",
    "    # Format time\n",
    "    utils.map_year_month(pivot, 'time', int(from_year), int(to_year))\n",
    "    assert pivot[['year', 'month']].isnull().sum().sum() == 0\n",
    "    \n",
    "    # Compute and save aggregations\n",
    "    utils.aggregate_by_groups(pivot, groups, output_folder, values=['precipitation'], done=done, batch=i)\n",
    "        \n",
    "    # Save micro data\n",
    "    pivot.to_csv(output_folder / full_name, index=False)\n",
    "    print(pivot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [05:18<00:00, 53.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Join all batches together\n",
    "files = [Path(x) for x in glob(str(output_folder / 'GPCC*.csv'))]\n",
    "files = [x for x in files if not x.name.startswith('GPCC_full')]\n",
    "groups = {}\n",
    "for file in files:\n",
    "    prefix = '_'.join(file.name.split('_')[:-1])\n",
    "    if prefix in groups:\n",
    "        groups[prefix].append(file)\n",
    "    else:\n",
    "        groups[prefix] = [file]\n",
    "        \n",
    "for prefix, files in tqdm(groups.items()):\n",
    "    dfs = [pd.read_csv(file, dtype=str) for file in files]\n",
    "    df = dfs[0].append(dfs[1:], ignore_index=True)\n",
    "    del dfs\n",
    "    \n",
    "    df.to_csv(output_folder / (prefix + '.csv'))\n",
    "    \n",
    "    for file in files:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>TRIBE_CODE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>GID_0</th>\n",
       "      <th>NAME_0</th>\n",
       "      <th>area_tribe</th>\n",
       "      <th>area_adm</th>\n",
       "      <th>area_inter</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GUANCHE</td>\n",
       "      <td>250</td>\n",
       "      <td>28.335400</td>\n",
       "      <td>-15.673500</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "      <td>7.485274e+09</td>\n",
       "      <td>5.060438e+11</td>\n",
       "      <td>7.112255e+09</td>\n",
       "      <td>MULTIPOLYGON (((-17.89487 27.78681, -17.89514 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JEBALA</td>\n",
       "      <td>312</td>\n",
       "      <td>34.850600</td>\n",
       "      <td>-5.280360</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1.673756e+10</td>\n",
       "      <td>5.060438e+11</td>\n",
       "      <td>2.028542e+07</td>\n",
       "      <td>MULTIPOLYGON (((-5.37708 35.91704, -5.37708 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RIF</td>\n",
       "      <td>651</td>\n",
       "      <td>34.790800</td>\n",
       "      <td>-3.718290</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2.027292e+10</td>\n",
       "      <td>5.060438e+11</td>\n",
       "      <td>7.560911e+06</td>\n",
       "      <td>MULTIPOLYGON (((-2.92593 35.29208, -2.92708 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADANGME</td>\n",
       "      <td>6</td>\n",
       "      <td>6.076851</td>\n",
       "      <td>0.270457</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>4.986379e+09</td>\n",
       "      <td>2.383243e+11</td>\n",
       "      <td>4.803454e+09</td>\n",
       "      <td>MULTIPOLYGON (((0.69465 5.77336, 0.69328 5.775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADELE</td>\n",
       "      <td>8</td>\n",
       "      <td>8.244284</td>\n",
       "      <td>0.673651</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>1.413803e+09</td>\n",
       "      <td>2.383243e+11</td>\n",
       "      <td>6.779161e+08</td>\n",
       "      <td>POLYGON ((0.45975 8.06680, 0.46512 8.07837, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NAME  TRIBE_CODE        LAT        LON GID_0 NAME_0    area_tribe  \\\n",
       "0  GUANCHE         250  28.335400 -15.673500   ESP  Spain  7.485274e+09   \n",
       "1   JEBALA         312  34.850600  -5.280360   ESP  Spain  1.673756e+10   \n",
       "2      RIF         651  34.790800  -3.718290   ESP  Spain  2.027292e+10   \n",
       "3  ADANGME           6   6.076851   0.270457   GHA  Ghana  4.986379e+09   \n",
       "4    ADELE           8   8.244284   0.673651   GHA  Ghana  1.413803e+09   \n",
       "\n",
       "       area_adm    area_inter  \\\n",
       "0  5.060438e+11  7.112255e+09   \n",
       "1  5.060438e+11  2.028542e+07   \n",
       "2  5.060438e+11  7.560911e+06   \n",
       "3  2.383243e+11  4.803454e+09   \n",
       "4  2.383243e+11  6.779161e+08   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-17.89487 27.78681, -17.89514 ...  \n",
       "1  MULTIPOLYGON (((-5.37708 35.91704, -5.37708 35...  \n",
       "2  MULTIPOLYGON (((-2.92593 35.29208, -2.92708 35...  \n",
       "3  MULTIPOLYGON (((0.69465 5.77336, 0.69328 5.775...  \n",
       "4  POLYGON ((0.45975 8.06680, 0.46512 8.07837, 0....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read shapes\n",
    "adm = gpd.read_file('../Shapefiles/ethnic_preprocessed/tribe_adm0.shp')\n",
    "adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1412/1412 [12:35<00:00,  1.87it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Find intersections per shape\n",
    "ethnic_df = []\n",
    "for idx, row in tqdm(adm.iterrows(), total=adm.shape[0]):\n",
    "    subdf = raster.intersection_ratio(locs, row['geometry'])\n",
    "    \n",
    "    if subdf is None or subdf.empty:\n",
    "        continue\n",
    "        \n",
    "    for col in ('NAME', 'TRIBE_CODE', 'GID_0'):\n",
    "        subdf[col] = row[col]\n",
    "        \n",
    "    ethnic_df.append(subdf)\n",
    "    \n",
    "ethnic_df = ethnic_df[0].append(ethnic_df[1:], ignore_index=True)\n",
    "ethnic_df.to_csv(ethnic_folder / 'ethnic_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_data_monthly_v2020_1891_1900_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1901_1910_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1911_1920_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1921_1930_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1931_1940_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:01<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1941_1950_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1951_1960_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:01<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1961_1970_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1971_1980_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1981_1990_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_1991_2000_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_2001_2010_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:01<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169440, 9)\n",
      "full_data_monthly_v2020_2011_2019_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152496, 9)\n"
     ]
    }
   ],
   "source": [
    "ethnic_df = pd.read_csv(ethnic_folder / 'ethnic_map.csv')\n",
    "assert ethnic_df.duplicated().sum() == 0\n",
    "\n",
    "time_groups = {'yearly': ['year'], 'monthly': ['year', 'month']}\n",
    "loc_groups = {'ethnic': ['NAME', 'TRIBE_CODE', 'GID_0']}\n",
    "\n",
    "groups = {}\n",
    "for loc_name, loc_group in loc_groups.items():\n",
    "    for time_name, time_group in time_groups.items():\n",
    "        groups[f'{loc_name}_{time_name}'] = loc_group + time_group\n",
    "        \n",
    "done = [Path(x).name for x in glob(str(ethnic_folder / 'GPCC_*.csv'))]\n",
    "done = []\n",
    "\n",
    "files = sorted(glob('../Data/Precipitaciones/full_data_monthly_v2020_*.csv'))\n",
    "for i, file in enumerate(files):\n",
    "    file = Path(file)\n",
    "    print(file.name)\n",
    "    \n",
    "    from_year, to_year = file.name.split('_')[-3:-1] \n",
    "    full_name = f'GPCC_full_{from_year}_{to_year}.csv'\n",
    "    if full_name in done:\n",
    "        continue\n",
    "    \n",
    "    # Read file and merge locations back\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.merge(ethnic_df, on=['lat', 'lon'])\n",
    "    \n",
    "    # Reshape to long\n",
    "    pivot = raster.weighted_pivot(\n",
    "        df,          \n",
    "        value_name='precipitation', \n",
    "        weight='intersection_area', \n",
    "        id_vars=('NAME', 'TRIBE_CODE', 'GID_0')\n",
    "    )\n",
    "    \n",
    "    # Format time\n",
    "    utils.map_year_month(pivot, 'time', int(from_year), int(to_year))\n",
    "    assert pivot[['year', 'month']].isnull().sum().sum() == 0\n",
    "    \n",
    "    # Compute and save aggregations\n",
    "    utils.aggregate_by_groups(pivot, groups, ethnic_folder, values=['precipitation'], done=done, batch=i)\n",
    "        \n",
    "    # Save micro data\n",
    "    pivot.to_csv(ethnic_folder / full_name, index=False)\n",
    "    print(pivot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  5.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# Join all batches together\n",
    "files = [Path(x) for x in glob(str(ethnic_folder / 'GPCC*.csv'))]\n",
    "files = [x for x in files if not x.name.startswith('GPCC_full')]\n",
    "groups = {}\n",
    "for file in files:\n",
    "    prefix = '_'.join(file.name.split('_')[:-1]).replace('_ethnic_ethnic', '_ethnic')\n",
    "    if prefix in groups:\n",
    "        groups[prefix].append(file)\n",
    "    else:\n",
    "        groups[prefix] = [file]\n",
    "        \n",
    "for prefix, files in tqdm(groups.items()):\n",
    "    dfs = [pd.read_csv(file, dtype=str) for file in files]\n",
    "    df = dfs[0].append(dfs[1:], ignore_index=True)\n",
    "    del dfs\n",
    "    \n",
    "    df.to_csv(ethnic_folder / (prefix + '.csv'))\n",
    "    \n",
    "    for file in files:\n",
    "        os.remove(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
