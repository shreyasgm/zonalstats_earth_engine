{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sd2/Moncho/zonalstats_earth_engine/.venv/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "import shapefile\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from projections.shapefiles import load_shapes, iter_records\n",
    "from projections.models import Records\n",
    "from projections import raster, utils\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = 'lon'\n",
    "lat = 'lat'\n",
    "country = 'country'\n",
    "output_folder = utils.make_path('../Output/Precipitaciones/Raster/GPCC/')\n",
    "location_folder = utils.make_path(output_folder / 'locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [01:46<00:00,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3787420, 2)\n",
      "Unique locs (291340, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-120.125</td>\n",
       "      <td>85.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-119.875</td>\n",
       "      <td>85.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.625</td>\n",
       "      <td>85.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-120.125</td>\n",
       "      <td>85.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-119.875</td>\n",
       "      <td>85.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lon     lat\n",
       "0 -120.125  85.875\n",
       "1 -119.875  85.875\n",
       "2 -119.625  85.875\n",
       "3 -120.125  85.625\n",
       "4 -119.875  85.625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in tqdm(glob('../Data/Precipitaciones/full_data_monthly_v2020_*.csv')):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df[['lon', 'lat']].copy())\n",
    "    del df\n",
    "    \n",
    "df = dfs[0].append(dfs[1:])\n",
    "del dfs\n",
    "\n",
    "print(df.shape)\n",
    "print('Unique locs', df.drop_duplicates(['lon', 'lat']).shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found, loading locs from df\n",
      "Separation: {'lat': 0.25, 'lon': 0.25}\n",
      "Converting to GeoDataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>adm0</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>raster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-120.125</td>\n",
       "      <td>85.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-120.12500 85.87500)</td>\n",
       "      <td>POLYGON ((-120.00000 86.00000, -120.00000 85.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-119.875</td>\n",
       "      <td>85.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-119.87500 85.87500)</td>\n",
       "      <td>POLYGON ((-119.75000 86.00000, -119.75000 85.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.625</td>\n",
       "      <td>85.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-119.62500 85.87500)</td>\n",
       "      <td>POLYGON ((-119.50000 86.00000, -119.50000 85.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-120.125</td>\n",
       "      <td>85.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-120.12500 85.62500)</td>\n",
       "      <td>POLYGON ((-120.00000 85.75000, -120.00000 85.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-119.875</td>\n",
       "      <td>85.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-119.87500 85.62500)</td>\n",
       "      <td>POLYGON ((-119.75000 85.75000, -119.75000 85.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lon     lat  adm0  adm1  adm2                     geometry  \\\n",
       "0 -120.125  85.875   NaN   NaN   NaN  POINT (-120.12500 85.87500)   \n",
       "1 -119.875  85.875   NaN   NaN   NaN  POINT (-119.87500 85.87500)   \n",
       "2 -119.625  85.875   NaN   NaN   NaN  POINT (-119.62500 85.87500)   \n",
       "3 -120.125  85.625   NaN   NaN   NaN  POINT (-120.12500 85.62500)   \n",
       "4 -119.875  85.625   NaN   NaN   NaN  POINT (-119.87500 85.62500)   \n",
       "\n",
       "                                              raster  \n",
       "0  POLYGON ((-120.00000 86.00000, -120.00000 85.7...  \n",
       "1  POLYGON ((-119.75000 86.00000, -119.75000 85.7...  \n",
       "2  POLYGON ((-119.50000 86.00000, -119.50000 85.7...  \n",
       "3  POLYGON ((-120.00000 85.75000, -120.00000 85.5...  \n",
       "4  POLYGON ((-119.75000 85.75000, -119.75000 85.5...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    locs = pd.read_csv(output_folder / 'unique_locs_gpcc.csv')\n",
    "except FileNotFoundError:\n",
    "    print('File not found, loading locs from df')\n",
    "    locs = df[[lon, lat]].drop_duplicates()\n",
    "    locs.loc[:, 'adm0'] = np.nan\n",
    "    locs.loc[:, 'adm1'] = np.nan\n",
    "    locs.loc[:, 'adm2'] = np.nan\n",
    "    locs.to_csv(output_folder / 'unique_locs_gpcc.csv', index=False)\n",
    "    \n",
    "locs = raster.create_by_separation(locs, lat='lat', lon='lon')\n",
    "locs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('../Shapefiles/preprocessed/all_countries_with_eth.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_worker(indices):\n",
    "    df = pd.read_csv(output_folder / 'unique_locs_gpcc.csv')\n",
    "    df = raster.create_by_separation(df, lat='lat', lon='lon')\n",
    "    geo_df = gpd.read_file('../Shapefiles/preprocessed/all_countries_with_eth.shp').loc[indices]\n",
    "    \n",
    "    for _, row in geo_df.iterrows():\n",
    "        portion = f\"_p{int(row['portion']):03d}\" if row['portion'] else \"\"\n",
    "        file_name = f\"{row['id']}{portion}.csv\"\n",
    "        row_path = location_folder / file_name\n",
    "        if row_path.exists():\n",
    "            continue\n",
    "\n",
    "        subset = raster.get_intersection_area(df, row['geometry'])\n",
    "        if subset is not None:\n",
    "            subset = subset[subset[\"intersection_area\"] > 0].copy()\n",
    "        else:\n",
    "            subset = pd.DataFrame()\n",
    "        subset.to_csv(row_path, index=False)\n",
    "    return 0\n",
    "\n",
    "n_processes = 15\n",
    "random_index = list(geo_df.index)\n",
    "np.random.shuffle(random_index)\n",
    "batch_size = (len(random_index) // n_processes) + 1\n",
    "indices = [random_index[i:i+batch_size] for i in range(0, len(random_index), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separation: Separation:{'lat': 0.25, 'lon': 0.25}\n",
      " Separation:Separation:Converting to GeoDataFrame{'lat': 0.25, 'lon': 0.25}Separation:Separation:  \n",
      "\n",
      "{'lat': 0.25, 'lon': 0.25}{'lat': 0.25, 'lon': 0.25}  \n",
      "Converting to GeoDataFrame\n",
      "{'lat': 0.25, 'lon': 0.25}Converting to GeoDataFrame{'lat': 0.25, 'lon': 0.25}\n",
      "Separation:\n",
      "Separation:\n",
      "Separation:\n",
      "Converting to GeoDataFrameConverting to GeoDataFrame  Converting to GeoDataFrame \n",
      "\n",
      "{'lat': 0.25, 'lon': 0.25}{'lat': 0.25, 'lon': 0.25}{'lat': 0.25, 'lon': 0.25}\n",
      "\n",
      "\n",
      "\n",
      "Converting to GeoDataFrameConverting to GeoDataFrameConverting to GeoDataFrame\n",
      "\n",
      "\n",
      "Separation:Separation:Separation:Separation:Separation:Separation:      {'lat': 0.25, 'lon': 0.25}{'lat': 0.25, 'lon': 0.25}{'lat': 0.25, 'lon': 0.25}{'lat': 0.25, 'lon': 0.25}{'lat': 0.25, 'lon': 0.25}\n",
      "{'lat': 0.25, 'lon': 0.25}\n",
      "\n",
      "\n",
      "\n",
      "Converting to GeoDataFrameConverting to GeoDataFrameConverting to GeoDataFrame\n",
      "Converting to GeoDataFrameConverting to GeoDataFrame\n",
      "\n",
      "\n",
      "Converting to GeoDataFrame\n",
      "\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor(n_processes) as ppe:\n",
    "    futures = [ppe.submit(mapper_worker, index) for index in indices]\n",
    "    for future in futures:\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122772it [03:31, 579.19it/s]\n"
     ]
    }
   ],
   "source": [
    "locs = []\n",
    "for file in tqdm(location_folder.glob('*.csv')):\n",
    "    subset = pd.read_csv(file)\n",
    "    \n",
    "    portion = re.findall(r'.*_p(\\d+)\\.csv', file.name)\n",
    "    if portion:\n",
    "        subset['id'] = re.findall(r'(.*)_p\\d+\\.csv', file.name)[0]\n",
    "        subset['portion'] = portion[0]\n",
    "    else:\n",
    "        subset['id'] = file.name[:-4]\n",
    "    locs.append(subset)\n",
    "\n",
    "\n",
    "locs = locs[0].append(locs[1:], ignore_index=True)\n",
    "locs.drop_duplicates(inplace=True)\n",
    "locs.to_csv(output_folder / 'loc_map.csv', index=False)\n",
    "print(locs.shape)\n",
    "locs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>intersection_area</th>\n",
       "      <th>id</th>\n",
       "      <th>portion</th>\n",
       "      <th>adm0</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414108</th>\n",
       "      <td>18.375</td>\n",
       "      <td>-102.875</td>\n",
       "      <td>3.752795e+08</td>\n",
       "      <td>MEX.16.24_1</td>\n",
       "      <td>NA</td>\n",
       "      <td>MEX</td>\n",
       "      <td>MEX.16</td>\n",
       "      <td>MEX.16.24_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387376</th>\n",
       "      <td>44.375</td>\n",
       "      <td>20.125</td>\n",
       "      <td>4.279528e+07</td>\n",
       "      <td>SRB.7.3_1</td>\n",
       "      <td>NA</td>\n",
       "      <td>SRB</td>\n",
       "      <td>SRB.7</td>\n",
       "      <td>SRB.7.3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451855</th>\n",
       "      <td>-5.875</td>\n",
       "      <td>-38.375</td>\n",
       "      <td>5.721834e+06</td>\n",
       "      <td>BRA.6.93_1</td>\n",
       "      <td>NA</td>\n",
       "      <td>BRA</td>\n",
       "      <td>BRA.6</td>\n",
       "      <td>BRA.6.93_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488565</th>\n",
       "      <td>58.875</td>\n",
       "      <td>34.625</td>\n",
       "      <td>4.015955e+08</td>\n",
       "      <td>RUS.49.7_1</td>\n",
       "      <td>NA</td>\n",
       "      <td>RUS</td>\n",
       "      <td>RUS.49</td>\n",
       "      <td>RUS.49.7_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571830</th>\n",
       "      <td>19.375</td>\n",
       "      <td>-5.625</td>\n",
       "      <td>1.957954e+08</td>\n",
       "      <td>MLI__BERABISH</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MLI__BERABISH</td>\n",
       "      <td>MLI__BERABISH</td>\n",
       "      <td>MLI__BERABISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lat      lon  intersection_area             id portion  \\\n",
       "414108  18.375 -102.875       3.752795e+08    MEX.16.24_1      NA   \n",
       "387376  44.375   20.125       4.279528e+07      SRB.7.3_1      NA   \n",
       "451855  -5.875  -38.375       5.721834e+06     BRA.6.93_1      NA   \n",
       "488565  58.875   34.625       4.015955e+08     RUS.49.7_1      NA   \n",
       "571830  19.375   -5.625       1.957954e+08  MLI__BERABISH    24.0   \n",
       "\n",
       "                 adm0           adm1           adm2  \n",
       "414108            MEX         MEX.16    MEX.16.24_1  \n",
       "387376            SRB          SRB.7      SRB.7.3_1  \n",
       "451855            BRA          BRA.6     BRA.6.93_1  \n",
       "488565            RUS         RUS.49     RUS.49.7_1  \n",
       "571830  MLI__BERABISH  MLI__BERABISH  MLI__BERABISH  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs = pd.read_csv(output_folder / 'loc_map.csv').fillna('NA')\n",
    "assert locs.duplicated().sum() == 0\n",
    "\n",
    "adm = {}\n",
    "for key in locs['id'].unique():\n",
    "    parts = key.split('.')\n",
    "    adm[key] = {0: parts[0], 1: '.'.join(parts[:2]), 2: key}\n",
    "    \n",
    "for i in range(3):\n",
    "    locs[f\"adm{i}\"] = locs['id'].apply(lambda x: adm[x][i])\n",
    "    \n",
    "locs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_data_monthly_v2020_1891_1900_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:43<00:00, 17.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1901_1910_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:39<00:00, 16.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1911_1920_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:39<00:00, 16.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1921_1930_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:39<00:00, 16.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1931_1940_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:38<00:00, 16.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1941_1950_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:40<00:00, 16.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1951_1960_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:38<00:00, 16.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1961_1970_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:40<00:00, 16.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1971_1980_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:40<00:00, 16.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1981_1990_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:40<00:00, 16.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_1991_2000_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:39<00:00, 16.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_2001_2010_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:40<00:00, 16.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774520, 9)\n",
      "full_data_monthly_v2020_2011_2019_025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|████████████████████████████████| 6/6 [01:30<00:00, 15.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197068, 9)\n"
     ]
    }
   ],
   "source": [
    "time_groups = {'yearly': ['year'], 'monthly': ['year', 'month']}\n",
    "loc_groups = {'country': ['adm0'], \n",
    "              'edo': ['adm0', 'adm1'], \n",
    "              'mun': ['adm0', 'adm1', 'adm2']}\n",
    "\n",
    "groups = {}\n",
    "for loc_name, loc_group in loc_groups.items():\n",
    "    for time_name, time_group in time_groups.items():\n",
    "        groups[f'{loc_name}_{time_name}'] = loc_group + time_group\n",
    "        \n",
    "\n",
    "done = [Path(x).name for x in glob(str(output_folder / 'GPCC_*.csv'))]\n",
    "\n",
    "files = sorted(glob('../Data/Precipitaciones/full_data_monthly_v2020_*.csv'))\n",
    "for i, file in enumerate(files):\n",
    "    file = Path(file)\n",
    "    print(file.name)\n",
    "    \n",
    "    from_year, to_year = file.name.split('_')[-3:-1] \n",
    "    full_name = f'GPCC_full_{from_year}_{to_year}.csv'\n",
    "    if full_name in done:\n",
    "        continue\n",
    "    \n",
    "    # Read file and merge locations back\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.merge(locs, on=['lat', 'lon'])\n",
    "    \n",
    "    # Reshape to long\n",
    "    pivot = raster.weighted_pivot(\n",
    "        df, \n",
    "        weight='intersection_area', \n",
    "        value_name='precipitation', \n",
    "        id_vars=['adm0', 'adm1', 'adm2']\n",
    "    )\n",
    "    \n",
    "    # Format time\n",
    "    utils.map_year_month(pivot, 'time', int(from_year), int(to_year))\n",
    "    assert pivot[['year', 'month']].isnull().sum().sum() == 0\n",
    "    \n",
    "    # Compute and save aggregations\n",
    "    utils.aggregate_by_groups(pivot, groups, output_folder, values=['precipitation'], done=done, batch=i)\n",
    "        \n",
    "    # Save micro data\n",
    "    pivot.to_csv(output_folder / full_name, index=False)\n",
    "    print(pivot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [06:38<00:00, 66.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Join all batches together\n",
    "files = [Path(x) for x in glob(str(output_folder / 'GPCC*.csv'))]\n",
    "files = [x for x in files if not x.name.startswith('GPCC_full')]\n",
    "groups = {}\n",
    "for file in files:\n",
    "    prefix = '_'.join(file.name.split('_')[:-1])\n",
    "    if prefix in groups:\n",
    "        groups[prefix].append(file)\n",
    "    else:\n",
    "        groups[prefix] = [file]\n",
    "        \n",
    "for prefix, files in tqdm(groups.items()):\n",
    "    dfs = [pd.read_csv(file, dtype=str) for file in files]\n",
    "    df = dfs[0].append(dfs[1:], ignore_index=True)\n",
    "    del dfs\n",
    "    \n",
    "    df.to_csv(output_folder / (prefix + '.csv'))\n",
    "    \n",
    "    for file in files:\n",
    "        os.remove(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
