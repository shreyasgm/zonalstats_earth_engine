{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sd2/Moncho/zonalstats_earth_engine/.venv/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tarfile\n",
    "\n",
    "import yaml\n",
    "\n",
    "from functools import partial\n",
    "from glob import glob, iglob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from projections.shapefiles import load_shapes, iter_records\n",
    "from projections.models import Records\n",
    "from projections.elevation import get_indices_by_file, SpacialTxt\n",
    "from projections import raster, utils\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_location_mapping(row_and_path):\n",
    "    row, path = row_and_path\n",
    "    shape = row['geometry']\n",
    "    \n",
    "    subset = raster.find_subset_with_intersection_area(IMAGE, shape)\n",
    "\n",
    "    if subset.empty:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write('')\n",
    "        return\n",
    "\n",
    "    subset['id'] = row['id']\n",
    "    \n",
    "    subset.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = Path('../Data/Elevation/Ruggedness')\n",
    "output_path = Path('../Output/Elevation/Ruggedness/')\n",
    "\n",
    "base_file = 'cellarea.txt'\n",
    "file_path = output_path / base_file[:-4]\n",
    "partial_path = file_path / 'partial'\n",
    "by_country_path = file_path / 'by_country'\n",
    "\n",
    "output_path.mkdir(exist_ok=True)\n",
    "file_path.mkdir(exist_ok=True)\n",
    "partial_path.mkdir(exist_ok=True)\n",
    "by_country_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map raster to polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('../Shapefiles/preprocessed/all_countries_with_eth.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 122772/122772 [13:59:29<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "n_processes = 30\n",
    "\n",
    "spacial_txt = SpacialTxt(read_path / base_file)\n",
    "spacial_txt.read(save=True)\n",
    "IMAGE = spacial_txt.get_xarray()\n",
    "\n",
    "iterator = partial(utils.yield_missing_shapes, save_path=partial_path, prefix=base_file[:-4])\n",
    "\n",
    "if n_processes == 1:\n",
    "    for row_and_path in tqdm(iterator(geo_df)):\n",
    "        save_location_mapping(row_and_path)\n",
    "else:\n",
    "    with ProcessPoolExecutor(n_processes) as tpe:\n",
    "        for _ in tqdm(\n",
    "            tpe.map(save_location_mapping, iterator(geo_df)), \n",
    "            total=geo_df.shape[0]\n",
    "        ):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union portions from different files and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 122772it [10:04, 203.17it/s]\n",
      "Saving: 100%|████████████████████████████| 48140/48140 [03:03<00:00, 262.92it/s]\n"
     ]
    }
   ],
   "source": [
    "df_by_region = {}\n",
    "for file in tqdm(partial_path.glob('*.csv'), desc='Reading'):\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "        \n",
    "    if 'id' not in df.columns:\n",
    "        df['id'] = df['adm2']\n",
    "        df['id'].fillna(df['adm1'], inplace=True)\n",
    "        df['id'].fillna(df['adm0'], inplace=True)\n",
    "    region = df.loc[0, 'id']\n",
    "    df_by_region.setdefault(region, []).append(df)\n",
    "\n",
    "for region, dfs in tqdm(df_by_region.items(), desc='Saving'):\n",
    "    df = utils.combine_dataframes(dfs)\n",
    "    df.to_feather(by_country_path / f'{region}.feather')\n",
    "    \n",
    "del df_by_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 100%|███████████████████████████| 48140/48140 [02:04<00:00, 388.03it/s]\n",
      "Grouping: 100%|██████████████████████████| 48140/48140 [05:02<00:00, 159.27it/s]\n"
     ]
    }
   ],
   "source": [
    "utils.aggregate_feather_splits_and_save(by_country_path, output_path / base_file, no_data_value=-9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional files with the same raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48140it [20:21, 39.41it/s] \n",
      "Reading: 100%|███████████████████████████| 48140/48140 [01:52<00:00, 429.19it/s]\n",
      "Grouping: 100%|██████████████████████████| 48140/48140 [04:53<00:00, 163.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tri.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48140it [20:07, 39.86it/s] \n",
      "Reading: 100%|███████████████████████████| 48140/48140 [01:52<00:00, 427.60it/s]\n",
      "Grouping: 100%|██████████████████████████| 48140/48140 [04:51<00:00, 165.09it/s]\n"
     ]
    }
   ],
   "source": [
    "files = ['slope.txt', 'tri.txt']\n",
    "for file in files:\n",
    "    print(file)\n",
    "    file_path = output_path / file[:-4]\n",
    "    file_by_country_path = file_path / 'by_country'\n",
    "    file_path.mkdir(exist_ok=True)\n",
    "    file_by_country_path.mkdir(exist_ok=True)\n",
    "\n",
    "    spacial_txt = SpacialTxt(read_path / file)\n",
    "    spacial_txt.read(save=True)\n",
    "    IMAGE = spacial_txt.get_xarray()\n",
    "    \n",
    "    for df_path in tqdm(by_country_path.glob('*.feather')):\n",
    "        df = pd.read_feather(df_path)\n",
    "        pol = utils.get_mock_polygon_from_df(df, increment=spacial_txt.increment)\n",
    "        subdf = raster.merge_df_to_array_by_lat_lon(df, IMAGE, pol)\n",
    "        if subdf.empty:\n",
    "            print(df_path.name, 'is empty')\n",
    "        else:\n",
    "            subdf.to_feather(file_by_country_path / df_path.name)\n",
    "            \n",
    "    utils.aggregate_feather_splits_and_save(file_by_country_path, output_path / file, no_data_value=-9999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
