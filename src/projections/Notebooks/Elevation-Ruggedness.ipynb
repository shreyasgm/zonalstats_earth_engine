{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sd2/Moncho/zonalstats_earth_engine/.venv/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tarfile\n",
    "\n",
    "import yaml\n",
    "\n",
    "from functools import partial\n",
    "from glob import glob, iglob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from projections.shapefiles import load_shapes, iter_records\n",
    "from projections.models import Records\n",
    "from projections.elevation import get_indices_by_file, SpacialTxt\n",
    "from projections import raster, utils\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_location_mapping(row_and_path):\n",
    "    \"\"\"\n",
    "    Common function used to obtain a mapping of polygons to\n",
    "    the rasters used by the IMAGE. \n",
    "    \n",
    "    This is not part of projections because it assumes IMAGE \n",
    "    exists in the global scope.\n",
    "    \"\"\"\n",
    "    row, path = row_and_path\n",
    "    shape = row['geometry']\n",
    "    \n",
    "    subset = raster.find_subset_with_intersection_area(IMAGE, shape)\n",
    "\n",
    "    if subset.empty:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write('')\n",
    "        return\n",
    "\n",
    "    subset['id'] = row['id']\n",
    "    \n",
    "    subset.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = Path('../Data/Elevation/Ruggedness')\n",
    "output_path = Path('../Output/Elevation/Ruggedness/')\n",
    "\n",
    "base_file = 'cellarea.txt'\n",
    "file_path = output_path / base_file[:-4]\n",
    "partial_path = file_path / 'partial'\n",
    "by_country_path = file_path / 'by_country'\n",
    "\n",
    "output_path.mkdir(exist_ok=True)\n",
    "file_path.mkdir(exist_ok=True)\n",
    "partial_path.mkdir(exist_ok=True)\n",
    "by_country_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map raster to polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SHP with all polygons (output of PreprocessingLocs.ipynb, also available in Drive)\n",
    "geo_df = gpd.read_file('../Shapefiles/preprocessed/all_countries_with_eth.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 122772/122772 [13:59:29<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "n_processes = 30\n",
    "\n",
    "spacial_txt = SpacialTxt(read_path / base_file)\n",
    "spacial_txt.read(save=True)\n",
    "IMAGE = spacial_txt.get_xarray()\n",
    "\n",
    "iterator = partial(utils.yield_missing_shapes, save_path=partial_path, prefix=base_file[:-4])\n",
    "\n",
    "if n_processes == 1:\n",
    "    for row_and_path in tqdm(iterator(geo_df)):\n",
    "        save_location_mapping(row_and_path)\n",
    "else:\n",
    "    with ProcessPoolExecutor(n_processes) as tpe:\n",
    "        for _ in tqdm(\n",
    "            tpe.map(save_location_mapping, iterator(geo_df)), \n",
    "            total=geo_df.shape[0]\n",
    "        ):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union portions from different files and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 122772it [10:04, 203.17it/s]\n",
      "Saving: 100%|████████████████████████████| 48140/48140 [03:03<00:00, 262.92it/s]\n"
     ]
    }
   ],
   "source": [
    "utils.union_and_save_portions(read_from=partial_path, save_in=by_country_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 100%|███████████████████████████| 48140/48140 [02:04<00:00, 388.03it/s]\n",
      "Grouping: 100%|██████████████████████████| 48140/48140 [05:02<00:00, 159.27it/s]\n"
     ]
    }
   ],
   "source": [
    "utils.aggregate_feather_splits_and_save(by_country_path, output_path / base_file, no_data_value=-9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional files with the same raster\n",
    "As there are multiple files sharing the same raster, match the values from these to the preprocessed raster and perform aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48140it [20:21, 39.41it/s] \n",
      "Reading: 100%|███████████████████████████| 48140/48140 [01:52<00:00, 429.19it/s]\n",
      "Grouping: 100%|██████████████████████████| 48140/48140 [04:53<00:00, 163.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tri.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48140it [20:07, 39.86it/s] \n",
      "Reading: 100%|███████████████████████████| 48140/48140 [01:52<00:00, 427.60it/s]\n",
      "Grouping: 100%|██████████████████████████| 48140/48140 [04:51<00:00, 165.09it/s]\n"
     ]
    }
   ],
   "source": [
    "files = ['slope.txt', 'tri.txt']\n",
    "for file in files:\n",
    "    print(file)\n",
    "    file_path = output_path / file[:-4]\n",
    "    file_by_country_path = file_path / 'by_country'\n",
    "    file_path.mkdir(exist_ok=True)\n",
    "    file_by_country_path.mkdir(exist_ok=True)\n",
    "\n",
    "    spacial_txt = SpacialTxt(read_path / file)\n",
    "    spacial_txt.read(save=True)\n",
    "    IMAGE = spacial_txt.get_xarray()\n",
    "    \n",
    "    for df_path in tqdm(by_country_path.glob('*.feather')):\n",
    "        df = pd.read_feather(df_path)\n",
    "        pol = utils.get_mock_polygon_from_df(df, increment=spacial_txt.increment)\n",
    "        subdf = raster.merge_df_to_array_by_lat_lon(df, IMAGE, pol)\n",
    "        if subdf.empty:\n",
    "            print(df_path.name, 'is empty')\n",
    "        else:\n",
    "            subdf.to_feather(file_by_country_path / df_path.name)\n",
    "            \n",
    "    utils.aggregate_feather_splits_and_save(file_by_country_path, output_path / file, no_data_value=-9999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
