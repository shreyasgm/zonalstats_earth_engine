{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisdasilva/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import yaml\n",
    "import gc\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from zipfile import ZipFile\n",
    "from glob import glob, iglob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from projections import geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = Path('../Output/GDELT')\n",
    "output_folder = Path('../Output/GDELT_Ethnic')\n",
    "collapse_folder = output_folder / 'collapsed'\n",
    "lat = 'ActionGeo_Lat'\n",
    "lon = 'ActionGeo_Long'\n",
    "geo_type_col = 'ActionGeo_Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>TRIBE_CODE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>GID_0</th>\n",
       "      <th>NAME_0</th>\n",
       "      <th>area_tribe</th>\n",
       "      <th>area_adm</th>\n",
       "      <th>area_inter</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GUANCHE</td>\n",
       "      <td>250</td>\n",
       "      <td>28.335400</td>\n",
       "      <td>-15.673500</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "      <td>7.485274e+09</td>\n",
       "      <td>5.060438e+11</td>\n",
       "      <td>7.112255e+09</td>\n",
       "      <td>MULTIPOLYGON (((-17.89487 27.78681, -17.89514 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JEBALA</td>\n",
       "      <td>312</td>\n",
       "      <td>34.850600</td>\n",
       "      <td>-5.280360</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1.673756e+10</td>\n",
       "      <td>5.060438e+11</td>\n",
       "      <td>2.028542e+07</td>\n",
       "      <td>MULTIPOLYGON (((-5.37708 35.91704, -5.37708 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RIF</td>\n",
       "      <td>651</td>\n",
       "      <td>34.790800</td>\n",
       "      <td>-3.718290</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2.027292e+10</td>\n",
       "      <td>5.060438e+11</td>\n",
       "      <td>7.560911e+06</td>\n",
       "      <td>MULTIPOLYGON (((-2.92593 35.29208, -2.92708 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADANGME</td>\n",
       "      <td>6</td>\n",
       "      <td>6.076851</td>\n",
       "      <td>0.270457</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>4.986379e+09</td>\n",
       "      <td>2.383243e+11</td>\n",
       "      <td>4.803454e+09</td>\n",
       "      <td>MULTIPOLYGON (((0.69465 5.77336, 0.69328 5.775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADELE</td>\n",
       "      <td>8</td>\n",
       "      <td>8.244284</td>\n",
       "      <td>0.673651</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>1.413803e+09</td>\n",
       "      <td>2.383243e+11</td>\n",
       "      <td>6.779161e+08</td>\n",
       "      <td>POLYGON ((0.45975 8.06680, 0.46512 8.07837, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NAME  TRIBE_CODE        LAT        LON GID_0 NAME_0    area_tribe  \\\n",
       "0  GUANCHE         250  28.335400 -15.673500   ESP  Spain  7.485274e+09   \n",
       "1   JEBALA         312  34.850600  -5.280360   ESP  Spain  1.673756e+10   \n",
       "2      RIF         651  34.790800  -3.718290   ESP  Spain  2.027292e+10   \n",
       "3  ADANGME           6   6.076851   0.270457   GHA  Ghana  4.986379e+09   \n",
       "4    ADELE           8   8.244284   0.673651   GHA  Ghana  1.413803e+09   \n",
       "\n",
       "       area_adm    area_inter  \\\n",
       "0  5.060438e+11  7.112255e+09   \n",
       "1  5.060438e+11  2.028542e+07   \n",
       "2  5.060438e+11  7.560911e+06   \n",
       "3  2.383243e+11  4.803454e+09   \n",
       "4  2.383243e+11  6.779161e+08   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-17.89487 27.78681, -17.89514 ...  \n",
       "1  MULTIPOLYGON (((-5.37708 35.91704, -5.37708 35...  \n",
       "2  MULTIPOLYGON (((-2.92593 35.29208, -2.92708 35...  \n",
       "3  MULTIPOLYGON (((0.69465 5.77336, 0.69328 5.775...  \n",
       "4  POLYGON ((0.45975 8.06680, 0.46512 8.07837, 0....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm = gpd.read_file('../Shapefiles/ethnic_preprocessed/tribe_adm0.shp')\n",
    "countries = set(adm['GID_0'])\n",
    "adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [7:10:24<00:00, 51.14s/it]   \n"
     ]
    }
   ],
   "source": [
    "zfiles = sorted(glob(str(input_folder / '*.zip')))\n",
    "\n",
    "try:\n",
    "    with open(output_folder / 'shapes_counts.yml', 'r') as f:\n",
    "        shapes = yaml.safe_load(f)\n",
    "except FileNotFoundError:\n",
    "    shapes = {}\n",
    "\n",
    "for zfile in tqdm(zfiles):\n",
    "    zfile = Path(zfile)\n",
    "    \n",
    "    # Extract files from ZIP\n",
    "    with ZipFile(zfile, 'r') as zf:\n",
    "        files = zf.namelist()\n",
    "        if all([f.split('.')[0] in shapes for f in files]):\n",
    "            continue\n",
    "        \n",
    "        zf.extractall()\n",
    "\n",
    "        dfs = []    \n",
    "        for f in files:\n",
    "            df = pd.read_feather(f)\n",
    "\n",
    "            # Store counts in dict\n",
    "            adm1_mask = df[geo_type_col] > 1\n",
    "            adm2_mask = np.logical_and(df[geo_type_col] > 2, df[geo_type_col] < 5)\n",
    "            shapes[f.split('.')[0]] = {'total': df.shape[0], \n",
    "                                       'adm1-2': int(adm1_mask.sum()),\n",
    "                                       'adm2': int(adm2_mask.sum())}\n",
    "\n",
    "            df = df[adm2_mask]\n",
    "            dfs.append(df[df['adm0'].apply(lambda x: x in countries)].copy())\n",
    "            os.remove(f)\n",
    "\n",
    "    # Join files together\n",
    "    if len(dfs) > 1:\n",
    "        df = dfs[0].append(dfs[1:], ignore_index=True)\n",
    "    else:\n",
    "        df = dfs[0]\n",
    "    del dfs\n",
    "    \n",
    "    df.drop(columns=['adm1', 'adm2', 'nearest_loc'], inplace=True)\n",
    "    \n",
    "    # Get unique locations\n",
    "    locs = df[[lat, lon]].drop_duplicates()\n",
    "    locs = gpd.GeoDataFrame(locs, geometry=gpd.points_from_xy(locs[lon], locs[lat]))\n",
    "    locs = locs.set_crs('EPSG:4326')\n",
    "\n",
    "    # Match geometries\n",
    "    locs = geometry.loc_match(adm, locs, ['NAME', 'TRIBE_CODE', 'GID_0'], verbose=False)\n",
    "    locs.drop(columns=['index_left', 'LAT', 'LON', 'NAME_0'], inplace=True)\n",
    "    \n",
    "    # Match locations back and save\n",
    "    df = df.merge(locs, on=[lat, lon])\n",
    "    df.drop(columns=['geometry', 'adm0'], inplace=True)\n",
    "    df.rename(columns={'GID_0': 'adm0'}, inplace=True)\n",
    "    df.to_csv(output_folder / zfile.with_suffix('.csv').name, index=False)\n",
    "\n",
    "    # Save shape statistics\n",
    "    with open(output_folder / 'shapes_counts.yml', 'w') as f:\n",
    "        yaml.dump(shapes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save shapes as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_folder / 'shapes_counts.yml', 'r') as f:\n",
    "    shapes = yaml.safe_load(f)\n",
    "\n",
    "shape_stats = []\n",
    "for k, v in shapes.items():\n",
    "    shape_stats.append({'date': k.split('_')[0], **v})\n",
    "    \n",
    "shape_stats = pd.DataFrame(shape_stats)\n",
    "shape_stats = shape_stats.groupby('date').sum()\n",
    "shape_stats.to_csv(output_folder / 'shapes_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collapsed(df, group_cols, dist_cols):   \n",
    "    for col in dist_cols:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "        \n",
    "    pivot = pd.pivot_table(df, \n",
    "                           index=group_cols, \n",
    "                           values=dist_cols,\n",
    "                           aggfunc=[np.mean, np.sum, np.median, np.std])\n",
    "    pivot.columns = ['_'.join(x[::-1]) for x in pivot.columns]\n",
    "    pivot['count'] = df.groupby(group_cols)[dist_cols[0]].count()\n",
    "    return pivot.reset_index()\n",
    "        \n",
    "    \n",
    "def get_collapsed_group(group, group_cols, dist_cols):\n",
    "    time_value, df = group\n",
    "    \n",
    "    df[group_cols] = df[group_cols].fillna('Not Available')\n",
    "    collapsed = get_collapsed(df, group_cols, dist_cols)\n",
    "    collapsed['time_value'] = time_value\n",
    "    \n",
    "    return collapsed\n",
    "\n",
    "        \n",
    "def increase_month(date: int):    \n",
    "    month = date % 100\n",
    "    if month == 12:\n",
    "        new_date = ((date // 100) + 1) * 100 + 1\n",
    "    else:\n",
    "        new_date = date + 1\n",
    "    return new_date\n",
    "\n",
    "\n",
    "def increase_week(date: int):    \n",
    "    week = date % 100\n",
    "    assert 0 < week < 54\n",
    "    \n",
    "    if week < 52:\n",
    "        new_date = date + 1\n",
    "    elif week == 53:\n",
    "        new_date = (date // 100 + 1) * 100 + 1\n",
    "    else:\n",
    "        year = date // 100\n",
    "        _, to_ = week_range(date)\n",
    "        if to_ == datetime(year, 12, 31):\n",
    "            new_date = (year + 1) * 100 + 1\n",
    "        else:\n",
    "            new_date = date + 1\n",
    "        \n",
    "    return new_date\n",
    "\n",
    "\n",
    "def increase_day(date: int):\n",
    "    date = datetime.strptime(str(date), '%Y%m%d')\n",
    "    date += timedelta(days=1)\n",
    "    return format_date(date)\n",
    "\n",
    "\n",
    "def format_date(date):\n",
    "    return int(datetime.strftime(date, '%Y%m%d'))\n",
    "\n",
    "\n",
    "def week_range(year_week):\n",
    "    year = year_week // 100\n",
    "    week = year_week % 100\n",
    "    assert 0 < week < 54\n",
    "    date = datetime.strptime(f'{year}01-0', '%Y%U-%w')\n",
    "    \n",
    "    if date.day == 1:\n",
    "        from_ = date\n",
    "        to_ = date + timedelta(days=6)\n",
    "    else:\n",
    "        from_ = datetime(year, 1, 1)\n",
    "        to_ = date\n",
    "    \n",
    "    if week > 1:\n",
    "        from_ = to_ + timedelta(days=1 + (7 * (week - 2)))\n",
    "        to_ = from_ + timedelta(days=6)\n",
    "        \n",
    "    if to_.year > year:\n",
    "        to_ = datetime(year, 12, 31)\n",
    "    \n",
    "    return format_date(from_), format_date(to_)\n",
    "\n",
    "\n",
    "def load_data(g, save_folder):\n",
    "    dfs = [pd.read_csv(file, dtype=str) for file in glob(str(save_folder / g))]\n",
    "    return dfs[0].append(dfs[1:], ignore_index=True)\n",
    "\n",
    "\n",
    "def load_yearly(save_folder, from_=1979, to_=2020):\n",
    "    for i in range(from_, to_ + 1):\n",
    "        yield i, load_data(f'{i}*.csv', save_folder)\n",
    "\n",
    "\n",
    "def load_monthly(save_folder, from_=197901, to_=202012):\n",
    "    while from_ <= to_:\n",
    "        yield from_, load_data(f'{from_}*.csv', save_folder)\n",
    "        from_ = increase_month(from_)\n",
    "        \n",
    "\n",
    "def load_weekly(save_folder, from_=197901, to_=202053):    \n",
    "    while from_ <= to_:\n",
    "        d1, d2 = week_range(from_)\n",
    "        m1, m2 = d1 // 100, d2 // 100\n",
    "        \n",
    "        df = load_data(f'{m1}.csv', save_folder)\n",
    "        if m1 != m2:\n",
    "            df = df.append(load_data(f'{m2}.csv', save_folder), ignore_index=True)\n",
    "        \n",
    "        df['SQLDATE'] = pd.to_numeric(df['SQLDATE'])\n",
    "        df = df.loc[np.logical_and(df['SQLDATE'] >= d1, df['SQLDATE'] <= d2)]        \n",
    "            \n",
    "        yield from_, df\n",
    "        \n",
    "        from_ = increase_week(from_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['EventCode']\n",
    "dist_cols = ['NumMentions', 'IsRootEvent', 'NumSources', 'NumArticles', 'AvgTone']\n",
    "time_funcs = {\n",
    "    'yearly': {'f': load_yearly},\n",
    "    'monthly': {'f': load_monthly},\n",
    "    'weekly': {'f': load_weekly}\n",
    "}\n",
    "groups = {\n",
    "    'ethnic': list(set(group_cols + ['adm0', 'NAME', 'TRIBE_CODE'])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yearly: 42it [06:40,  9.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ethnic\n",
      "Saving df with shape (127303, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monthly: 504it [06:57,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ethnic\n",
      "Saving df with shape (127303, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weekly: 2226it [20:31,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ethnic\n",
      "Saving df with shape (127303, 26)\n"
     ]
    }
   ],
   "source": [
    "processed = [Path(x).name for x in glob(str(collapse_folder / '*.csv'))]\n",
    "\n",
    "# For each time aggregation\n",
    "for time_name, time_attrs in time_funcs.items():\n",
    "    n_batches = time_attrs.get('batch', 1)\n",
    "    batch_size = 42 // n_batches + int(42 % n_batches > 0)\n",
    "    \n",
    "    collapsed = {group_name: [] for group_name in groups}\n",
    "    \n",
    "    # If all groups for a time value has been processed, no need to load the data\n",
    "    if sum([time_name in x for x in processed]) == len(groups):\n",
    "        continue\n",
    "    \n",
    "    # Load the data and collapse each group\n",
    "    for group in tqdm(time_attrs['f'](output_folder), desc=f\"{time_name}\"):\n",
    "\n",
    "        for group_name, group_cols in groups.items():  \n",
    "            fname = f'GDELT_{group_name}_{time_name}.csv'\n",
    "            if fname in processed:\n",
    "                continue\n",
    "\n",
    "            collapsed[group_name].append(\n",
    "                get_collapsed_group(group, group_cols=group_cols, dist_cols=dist_cols)\n",
    "            )\n",
    "\n",
    "    # Append and save collapse\n",
    "#     df = df.merge(locs, on=[lat, lon])\n",
    "#     df.drop(columns=['geometry', 'adm0'], inplace=True)\n",
    "#     df.rename(columns={'GID_0': 'adm0'}, inplace=True)\n",
    "#     df.to_csv(output_folder / zfile.with_suffix('.csv').name, index=False)\n",
    "\n",
    "    # Save shape statistics\n",
    "    with open(output_folder / 'shapes_counts.yml', 'w') as f:\n",
    "        yaml.dump(shapes, f)\n",
    "        \n",
    "    for group_name, dfs in collapsed.items():\n",
    "        fname = f'GDELT_{group_name}_{time_name}.csv'\n",
    "        print(f'Appending {group_name}')\n",
    "        df = dfs[0].append(dfs[1:], ignore_index=True)\n",
    "        df.drop_duplicates(groups[group_name], inplace=True)\n",
    "\n",
    "        print('Saving df with shape', df.shape)\n",
    "        df.to_csv(collapse_folder / fname, index=False)\n",
    "        del df\n",
    "\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
