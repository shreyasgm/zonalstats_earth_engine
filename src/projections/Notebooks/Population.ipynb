{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sd2/Moncho/zonalstats_earth_engine/.venv/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import re\n",
    "\n",
    "import shutil\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from projections import raster, utils\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_location_mapping(row_and_path):\n",
    "    \"\"\"\n",
    "    Common function used to obtain a mapping of polygons to\n",
    "    the rasters used by the IMAGE. \n",
    "    \n",
    "    This is not part of projections because it assumes IMAGE \n",
    "    exists in the global scope.\n",
    "    \"\"\"\n",
    "    row, path = row_and_path\n",
    "    shape = row['geometry']\n",
    "    \n",
    "    subset = raster.find_subset_with_intersection_area(IMAGE, shape)\n",
    "\n",
    "    if subset.empty:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write('')\n",
    "        return\n",
    "\n",
    "    subset['id'] = row['id']\n",
    "    \n",
    "    subset.to_csv(path, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = Path('../Data/Population')\n",
    "output_path = utils.make_path('../Output/Population/')\n",
    "partial_path = utils.make_path(output_path / 'partial')\n",
    "by_country_path = utils.make_path(output_path / 'by_country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that all TIF share the same coordinates\n",
    "x = None\n",
    "y = None\n",
    "no_data_value = None\n",
    "\n",
    "all_tif = sorted(read_path.glob('**/*.tif'))\n",
    "for tif in all_tif:\n",
    "    image = utils.read_tif(tif)\n",
    "    if x is None:\n",
    "        x = image.x\n",
    "        y = image.y\n",
    "        no_data_value = image._FillValue\n",
    "    else:\n",
    "        assert np.all(x == image.x) and np.all(y == image.y), tif\n",
    "        assert no_data_value == image._FillValue\n",
    "        \n",
    "base_file = all_tif[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map raster to polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SHP with all polygons (output of PreprocessingLocs.ipynb, also available in Drive)\n",
    "geo_df = gpd.read_file('../Shapefiles/preprocessed/all_countries_with_eth.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████▊  | 113695/122772 [19:08:09<12:25:14,  4.93s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▊  | 113696/122772 [19:08:32<16:32:53,  6.56s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▊  | 113703/122772 [19:09:15<12:32:18,  4.98s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▊  | 113704/122772 [19:09:42<27:21:24, 10.86s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▊  | 113713/122772 [19:10:59<12:16:37,  4.88s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▊  | 113716/122772 [19:11:56<33:55:09, 13.48s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114264/122772 [19:27:11<35:09:24, 14.88s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114265/122772 [19:27:25<40:03:10, 16.95s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114266/122772 [19:27:41<36:36:44, 15.50s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114271/122772 [19:28:35<28:40:40, 12.14s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114272/122772 [19:28:55<34:04:46, 14.43s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114279/122772 [19:31:12<40:39:16, 17.23s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114280/122772 [19:31:28<49:50:14, 21.13s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114285/122772 [19:32:52<37:09:50, 15.76s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114286/122772 [19:32:54<28:01:41, 11.89s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114289/122772 [19:33:26<24:36:19, 10.44s/it]IOStream.flush timed out\n",
      " 93%|██████████████████████████▉  | 114297/122772 [19:34:33<15:24:59,  6.55s/it]IOStream.flush timed out\n",
      " 93%|███████████████████████████  | 114306/122772 [19:36:00<19:57:15,  8.49s/it]IOStream.flush timed out\n",
      " 93%|███████████████████████████  | 114307/122772 [19:36:32<25:43:52, 10.94s/it]IOStream.flush timed out\n",
      " 93%|███████████████████████████  | 114308/122772 [19:36:53<44:03:07, 18.74s/it]IOStream.flush timed out\n",
      " 93%|███████████████████████████  | 114582/122772 [19:55:14<29:22:32, 12.91s/it]IOStream.flush timed out\n",
      " 93%|███████████████████████████  | 114583/122772 [19:55:27<30:07:01, 13.24s/it]IOStream.flush timed out\n",
      " 93%|████████████████████████████  | 114706/122772 [19:57:08<5:02:50,  2.25s/it]IOStream.flush timed out\n",
      " 93%|███████████████████████████  | 114709/122772 [19:57:27<10:47:50,  4.82s/it]IOStream.flush timed out\n",
      " 93%|███████████████████████████  | 114712/122772 [19:58:15<21:47:22,  9.73s/it]IOStream.flush timed out\n",
      " 93%|███████████████████████████  | 114715/122772 [19:59:05<29:53:47, 13.36s/it]IOStream.flush timed out\n",
      " 94%|███████████████████████████▏ | 115190/122772 [20:19:28<10:14:19,  4.86s/it]IOStream.flush timed out\n",
      " 94%|████████████████████████████▏ | 115412/122772 [20:32:36<6:53:48,  3.37s/it]IOStream.flush timed out\n",
      " 94%|████████████████████████████▏ | 115518/122772 [20:35:01<2:22:53,  1.18s/it]IOStream.flush timed out\n",
      " 94%|████████████████████████████▏ | 115521/122772 [20:35:15<4:16:39,  2.12s/it]IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      " 94%|████████████████████████████▏ | 115524/122772 [20:35:40<9:03:14,  4.50s/it]IOStream.flush timed out\n",
      " 94%|████████████████████████████▏ | 115525/122772 [20:35:45<7:33:28,  3.75s/it]IOStream.flush timed out\n",
      " 94%|███████████████████████████▎ | 115527/122772 [20:36:19<20:14:37, 10.06s/it]IOStream.flush timed out\n",
      " 94%|███████████████████████████▎ | 115669/122772 [20:38:54<11:40:44,  5.92s/it]IOStream.flush timed out\n",
      " 94%|████████████████████████████▎ | 115891/122772 [20:51:15<8:23:39,  4.39s/it]IOStream.flush timed out\n",
      " 94%|███████████████████████████▍ | 115986/122772 [20:53:32<12:11:37,  6.47s/it]IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      " 95%|████████████████████████████▍ | 116435/122772 [21:10:36<3:39:56,  2.08s/it]IOStream.flush timed out\n",
      " 95%|████████████████████████████▍ | 116438/122772 [21:11:01<6:05:53,  3.47s/it]IOStream.flush timed out\n",
      " 95%|████████████████████████████▌ | 116958/122772 [21:28:58<2:36:25,  1.61s/it]IOStream.flush timed out\n",
      " 95%|████████████████████████████▌ | 117061/122772 [21:31:34<7:12:21,  4.54s/it]IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      " 95%|███████████████████████████▋ | 117063/122772 [21:31:58<11:52:22,  7.49s/it]IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      " 96%|████████████████████████████▊ | 117968/122772 [22:05:30<4:32:41,  3.41s/it]IOStream.flush timed out\n",
      " 96%|███████████████████████████▉ | 118074/122772 [22:08:24<14:01:18, 10.74s/it]IOStream.flush timed out\n",
      " 97%|███████████████████████████▉ | 118485/122772 [22:25:05<12:30:24, 10.50s/it]IOStream.flush timed out\n",
      " 97%|████████████████████████████▉ | 118489/122772 [22:25:20<7:52:01,  6.61s/it]IOStream.flush timed out\n",
      " 97%|████████████████████████████▉ | 118655/122772 [22:28:02<1:02:36,  1.10it/s]IOStream.flush timed out\n",
      " 97%|█████████████████████████████ | 119013/122772 [22:44:49<3:56:58,  3.78s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████ | 119017/122772 [22:45:37<7:17:06,  6.98s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████ | 119018/122772 [22:46:17<8:59:13,  8.62s/it]IOStream.flush timed out\n",
      " 97%|████████████████████████████ | 119022/122772 [22:47:02<12:13:01, 11.73s/it]IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      " 97%|████████████████████████████ | 119023/122772 [22:47:55<20:18:39, 19.50s/it]IOStream.flush timed out\n",
      " 97%|████████████████████████████ | 119024/122772 [22:49:07<35:33:46, 34.16s/it]IOStream.flush timed out\n",
      " 97%|████████████████████████████ | 119034/122772 [22:51:34<14:31:22, 13.99s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████ | 119053/122772 [22:52:58<4:49:35,  4.67s/it]IOStream.flush timed out\n",
      " 97%|████████████████████████████ | 119055/122772 [22:53:25<10:05:07,  9.77s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████ | 119061/122772 [22:53:40<3:13:04,  3.12s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████ | 119071/122772 [22:54:40<4:02:08,  3.93s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████ | 119073/122772 [22:55:04<8:05:44,  7.88s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████▏| 119443/122772 [23:08:20<3:04:22,  3.32s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████▏| 119447/122772 [23:08:59<7:49:22,  8.47s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████▏| 119451/122772 [23:09:14<5:31:50,  6.00s/it]IOStream.flush timed out\n",
      " 97%|████████████████████████████▏| 119461/122772 [23:11:01<15:44:56, 17.12s/it]IOStream.flush timed out\n",
      " 97%|████████████████████████████▏| 119463/122772 [23:11:28<13:49:29, 15.04s/it]IOStream.flush timed out\n",
      " 97%|█████████████████████████████▏| 119680/122772 [23:14:47<1:47:31,  2.09s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▎| 119878/122772 [23:30:26<8:12:15, 10.21s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▎| 119880/122772 [23:30:42<7:57:16,  9.90s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▎| 119881/122772 [23:31:08<9:24:13, 11.71s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▎| 120023/122772 [23:34:57<1:09:11,  1.51s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▎| 120029/122772 [23:35:49<3:58:33,  5.22s/it]IOStream.flush timed out\n",
      " 98%|████████████████████████████▍| 120282/122772 [23:47:36<10:19:57, 14.94s/it]IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      " 98%|█████████████████████████████▍| 120289/122772 [23:49:27<9:35:07, 13.90s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▍| 120292/122772 [23:49:59<7:12:50, 10.47s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▍| 120294/122772 [23:50:14<5:48:28,  8.44s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▍| 120296/122772 [23:50:47<8:10:45, 11.89s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▍| 120307/122772 [23:52:14<5:59:09,  8.74s/it]IOStream.flush timed out\n",
      " 98%|█████████████████████████████▍| 120308/122772 [23:52:22<5:42:36,  8.34s/it]IOStream.flush timed out\n",
      " 98%|████████████████████████████▍| 120310/122772 [23:53:04<10:03:06, 14.70s/it]IOStream.flush timed out\n",
      " 98%|████████████████████████████▍| 120311/122772 [23:53:51<16:48:30, 24.59s/it]IOStream.flush timed out\n",
      "100%|███████████████████████████████▉| 122585/122772 [24:08:59<02:12,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "n_processes = 30\n",
    "\n",
    "IMAGE = utils.read_tif(base_file)\n",
    "\n",
    "iterator = partial(utils.yield_missing_shapes, save_path=partial_path, prefix=base_file.name[:-4])\n",
    "\n",
    "if n_processes == 1:\n",
    "    for row_and_path in tqdm(iterator(geo_df)):\n",
    "        save_location_mapping(row_and_path)\n",
    "else:\n",
    "    with ThreadPoolExecutor(n_processes) as tpe:\n",
    "        for _ in tqdm(\n",
    "            tpe.map(save_location_mapping, iterator(geo_df)), \n",
    "            total=geo_df.shape[0]\n",
    "        ):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.union_and_save_portions(read_from=partial_path, save_in=by_country_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate all files with same raster\n",
    "As there are multiple TIFs but all of them share the same raster, match the values from these to the preprocessed raster and perform aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with 10 processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 100%|████████████████████████████| 48136/48136 [40:32<00:00, 19.79it/s]\n",
      "Grouping: 100%|███████████████████████████| 48136/48136 [35:39<00:00, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpw_v4_population_count_rev11_2000_30_sec.tif\n"
     ]
    }
   ],
   "source": [
    "def aggregate_one(file):\n",
    "    partial_path = make_partial_path(file.parent.name)\n",
    "    output_path = partial_path.parent / file.name\n",
    "    if output_path.exists():\n",
    "        return file.name\n",
    "    \n",
    "    file_path = partial_path.parent / file.name[:-4]\n",
    "    file_path.mkdir(exist_ok=True)\n",
    "\n",
    "    IMAGE = utils.read_tif(file)\n",
    "    increment = raster.get_increment_from_tif(IMAGE)\n",
    "    \n",
    "    for df_path in by_country_path.glob('*.feather'):\n",
    "        subdf_path = file_path / df_path.name\n",
    "        if subdf_path.exists():\n",
    "            continue\n",
    "            \n",
    "        df = pd.read_feather(df_path)\n",
    "        pol = utils.get_mock_polygon_from_df(df, increment=increment)\n",
    "        subdf = raster.merge_df_to_array_by_lat_lon(df, IMAGE, pol)\n",
    "        if subdf.empty:\n",
    "            print(df_path.name, 'is empty')\n",
    "        else:\n",
    "            subdf.to_feather(subdf_path)\n",
    "            \n",
    "    utils.aggregate_feather_splits_and_save(\n",
    "        input_path=file_path, \n",
    "        output_path=output_path, \n",
    "        no_data_value=no_data_value\n",
    "    )\n",
    "    shutil.rmtree(file_path)\n",
    "    return file.name\n",
    "    \n",
    "n_processes = min(len(all_tif), 10)\n",
    "print(f\"Running with {n_processes} processes\")\n",
    "if n_processes == 1:\n",
    "    for tif_file in all_tif:\n",
    "        print(aggregate_one(tif_file))\n",
    "else:\n",
    "    with ThreadPoolExecutor(n_processes) as tpe:\n",
    "        for name in tpe.map(aggregate_one, all_tif):\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join results\n",
    "Combine all the intermediate results and save a consolidated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_population_df(file):\n",
    "    df = utils.robust_read(file)\n",
    "    year = get_year_from_population_file(file)\n",
    "    value_name = f'{file.parent.name}_{year}'\n",
    "    df.rename(columns={'value': value_name}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_year_from_population_file(file):\n",
    "    return re.findall(\".*_(\\d{4})_.*\", file.name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "\n",
    "for file in tqdm(output_path.glob('**/*.csv')):\n",
    "    if file.parent.name == 'partial':\n",
    "        continue\n",
    "        \n",
    "    field = read_population_df(file)\n",
    "    if field.empty:\n",
    "        continue\n",
    "    elif df is None:\n",
    "        df = field\n",
    "    else:\n",
    "        df = df.merge(field.drop(columns='intersection_area'), on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path / \"population.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
